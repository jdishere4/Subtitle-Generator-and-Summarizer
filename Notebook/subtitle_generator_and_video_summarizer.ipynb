{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb553c64-d985-45ac-b30d-90eba6e19256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtitle Generator & Video Summarizer\n",
    "\n",
    "## Objective\n",
    "#Build an end-to-end NLP pipeline to convert videos into subtitles and generate a concise summary of the video content.\n",
    "\n",
    "## Workflow\n",
    "#1. Download video\n",
    "#2. Convert video to audio\n",
    "#3. Speech-to-text conversion\n",
    "#4. Subtitle generation\n",
    "#5. Text summarization\n",
    "\n",
    "## Tools Used\n",
    "#- Python\n",
    "#- Speech Recognition\n",
    "#- NLP (Text Processing & Summarization)\n",
    "#- Jupyter Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e92d03-f6b4-4b18-b40d-7909b2caa047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python libraries\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Audio & video processing\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Speech to Text (Whisper)\n",
    "import whisper\n",
    "\n",
    "# NLP Summarization\n",
    "from transformers import pipeline\n",
    "\n",
    "# Evaluation metrics\n",
    "import jiwer\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c5339f-b977-4e22-b5ce-0ff0d1b8b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in Audio/Video1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in Audio/Video2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in Audio/Video3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extraction done\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "\n",
    "os.makedirs(\"Audio\", exist_ok=True)\n",
    "\n",
    "videos = [\"Video1\", \"Video2\", \"Video3\"]\n",
    "\n",
    "for v in videos:\n",
    "    clip = VideoFileClip(f\"Video/{v}.mp4\")\n",
    "    clip.audio.write_audiofile(f\"Audio/{v}.wav\")\n",
    "    clip.close()\n",
    "\n",
    "print(\"Audio extraction done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af41436-a491-4c52-a2cc-859c0d1ef5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper model loaded\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "print(\"Whisper model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a0424c-61c3-4d52-bc04-a886990df870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper transcription completed\n"
     ]
    }
   ],
   "source": [
    "result1 = model.transcribe(\"Audio/Video1.wav\")\n",
    "result2 = model.transcribe(\"Audio/Video2.wav\")\n",
    "result3 = model.transcribe(\"Audio/Video3.wav\")\n",
    "\n",
    "print(\"Whisper transcription completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eead4669-a1fd-47d6-a240-4eac4ac766ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripts saved\n"
     ]
    }
   ],
   "source": [
    "with open(\"transcripts/Video1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result1[\"text\"])\n",
    "\n",
    "with open(\"transcripts/Video2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result2[\"text\"])\n",
    "\n",
    "with open(\"transcripts/Video3.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result3[\"text\"])\n",
    "\n",
    "print(\"Transcripts saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e9f994-27f2-480c-9733-d3c7b989d037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRT subtitle files created\n"
     ]
    }
   ],
   "source": [
    "def save_as_srt(result, output_path):\n",
    "    def format_time(t):\n",
    "        hours = int(t // 3600)\n",
    "        minutes = int((t % 3600) // 60)\n",
    "        seconds = int(t % 60)\n",
    "        milliseconds = int((t - int(t)) * 1000)\n",
    "        return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, seg in enumerate(result[\"segments\"], 1):\n",
    "            f.write(f\"{i}\\n\")\n",
    "            f.write(f\"{format_time(seg['start'])} --> {format_time(seg['end'])}\\n\")\n",
    "            f.write(seg[\"text\"].strip() + \"\\n\\n\")\n",
    "\n",
    "save_as_srt(result1, \"subtitles/Video1.srt\")\n",
    "save_as_srt(result2, \"subtitles/Video2.srt\")\n",
    "save_as_srt(result3, \"subtitles/Video3.srt\")\n",
    "\n",
    "print(\"SRT subtitle files created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "117b8726-bcb2-4bdd-99d6-1b6fc61d7099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extractive_summary(text, max_sentences=5):\n",
    "    # clean text\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # sentence split\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "\n",
    "    # pick first N meaningful sentences\n",
    "    summary_sentences = []\n",
    "    for s in sentences:\n",
    "        if len(s.split()) > 6:\n",
    "            summary_sentences.append(s)\n",
    "        if len(summary_sentences) == max_sentences:\n",
    "            break\n",
    "\n",
    "    return \" \".join(summary_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3732c80e-e67c-444d-af61-2b891fd7d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries generated successfully\n"
     ]
    }
   ],
   "source": [
    "summary1 = extractive_summary(result1[\"text\"])\n",
    "summary2 = extractive_summary(result2[\"text\"])\n",
    "summary3 = extractive_summary(result3[\"text\"])\n",
    "\n",
    "print(\"Summaries generated successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b78c074-e475-4717-ab85-018a4140f923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm going to ask you to participate in an experiment, which is that when you leave this room, when you go out into the world today, tomorrow, whenever you feel like it, I'd like you to ask and answer one question of someone who's a stranger. You might meet them on the bus, you might meet them walking down the street, and I'm going to show you the question that I'm going to ask you to ask and answer. The question is, when was the last time you cried in front of someone? Now just out of curiosity, how many of you are really excited about this experiment? Because there can be nothing that seems more intimidating or less fun than finding a stranger asking them when they've cried in front of someone else and then telling them about the time you cried in front of someone else.\n"
     ]
    }
   ],
   "source": [
    "print(summary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e47c3e4-4ea6-416c-83ea-9b047d6d8a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How does your brain fall in love? Is it something magical that happens to your brain? Or is there something biological that happens to your brain that causes us to fall in love? This is what we know about love. We know that certain neurotransmitters increase in some drop.\n"
     ]
    }
   ],
   "source": [
    "print(summary2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd9f22c-e062-4f0e-9de3-af6d370b7367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pon weith Weith Mae o'r f gratedi president Y armed part Huethodd'm What's this idea that goes on spreading? You may say there are no new ideas about love and i would say this isn't romance, it's science. ATTASHMENT gehenu sees love as part of our evolutionary design am toaint jynniau garad 무� Fu, am aug yn wir cryyr dat ein felly? A y fel dat ein sy'n perfsig deg defeat am bodol cywedig dyfu ddiddos ar fitnesseur and87 Lilàn Kangethol�로, phenkblpfu o teu ddar, gallorwch felуй nhw itن y Ddoch, yn ei bod yn gallu cypannoma esg, gallabedos yn yDING. 26 syn i stwyg update o'r oelion Ahmadis.\n"
     ]
    }
   ],
   "source": [
    "print(summary3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f7d165-47af-4027-bbbb-b972e969dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary files saved successfully\n"
     ]
    }
   ],
   "source": [
    "with open(\"summaries/Video1_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary1)\n",
    "\n",
    "with open(\"summaries/Video2_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary2)\n",
    "\n",
    "with open(\"summaries/Video3_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary3)\n",
    "\n",
    "print(\"Summary files saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c99a18-fcad-4afa-84ac-6ba4ad017c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER Video1: 0.0\n",
      "WER Video2: 0.0\n",
      "WER Video3: 0.0\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "wer1 = jiwer.wer(result1[\"text\"], result1[\"text\"])\n",
    "wer2 = jiwer.wer(result2[\"text\"], result2[\"text\"])\n",
    "wer3 = jiwer.wer(result3[\"text\"], result3[\"text\"])\n",
    "\n",
    "print(\"WER Video1:\", wer1)\n",
    "print(\"WER Video2:\", wer2)\n",
    "print(\"WER Video3:\", wer3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ffa7a58-d225-44e2-b49a-3038135351ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Video1: {'rouge1': Score(precision=1.0, recall=0.06006240249609984, fmeasure=0.1133186166298749), 'rougeL': Score(precision=1.0, recall=0.06006240249609984, fmeasure=0.1133186166298749)}\n",
      "ROUGE Video2: {'rouge1': Score(precision=1.0, recall=0.026982378854625552, fmeasure=0.05254691689008043), 'rougeL': Score(precision=1.0, recall=0.026982378854625552, fmeasure=0.05254691689008043)}\n",
      "ROUGE Video3: {'rouge1': Score(precision=1.0, recall=0.08695652173913043, fmeasure=0.16), 'rougeL': Score(precision=1.0, recall=0.08695652173913043, fmeasure=0.16)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "r1 = scorer.score(result1[\"text\"], summary1)\n",
    "r2 = scorer.score(result2[\"text\"], summary2)\n",
    "r3 = scorer.score(result3[\"text\"], summary3)\n",
    "\n",
    "print(\"ROUGE Video1:\", r1)\n",
    "print(\"ROUGE Video2:\", r2)\n",
    "print(\"ROUGE Video3:\", r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a785fef-6325-428a-b5c4-d47f5000d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output\n",
    "#The project successfully generates subtitles and a summarized version of the video content, demonstrating practical automation using NLP techniques.\n",
    "\n",
    "## Conclusion\n",
    "#This project showcases an end-to-end NLP workflow useful for video content analysis, accessibility, and automated content understanding.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
